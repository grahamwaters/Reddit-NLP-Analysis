{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "# Evaluate the model using cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import auc and roc_curve\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "# import the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "# import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import RMSE and MSE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# import AUC and ROC\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "# import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# adaboost imports\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "# import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tree imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from alive_progress import alive_bar\n",
    "\n",
    "# import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will use the following models\n",
    "\n",
    "0. A Baseline Model (50% Accuracy)\n",
    "\n",
    "1. Logistic Regression - \n",
    "2. Gradient Boosting Classifier\n",
    "3. Decision Tree Classifier\n",
    "4. Naive Bayes Classifier\n",
    "5. Random Forest Classifier\n",
    "6. Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imports from sklearn\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "# Kernel SVC\n",
    "from sklearn.svm import SVC\n",
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and Evaluation imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "# import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Selection using SelectKBest\n",
    "# import SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# import f_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# variance_inflation_factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# import VarianceThreshold\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of parameters for each model type\n",
    "\n",
    "param_defaults = {\n",
    "    'logisticregression': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    },\n",
    "    'decisiontree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    },\n",
    "    'randomforestclassifier': {\n",
    "        'n_estimators': [10, 50, 100, 200, 300],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_samples_split': [2, 3, 4],\n",
    "        'min_samples_leaf': [1, 2, 3]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'n_estimators': [10, 50, 100, 200, 300, 400, 500],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
    "        'reg_lambda': [0, 0.25, 0.5, 0.75, 1]\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'n_estimators': [10, 50, 100, 200, 300, 400, 500],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'loss': ['deviance', 'exponential'],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'n_estimators': [10, 50, 100, 200, 300, 400, 500],\n",
    "        'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    },\n",
    "    'naive_bayes': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_results(model,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train,param_defaults,gridsearch=False):\n",
    "    \"\"\"\n",
    "    save_results takes in a model and a master results dataframe and saves the model and the master results dataframe as a pickle file\n",
    "\n",
    "    _extended_summary_\n",
    "\n",
    "    :param model: _description_\n",
    "    :type model: _type_\n",
    "    :param master_results_dataframe: _description_\n",
    "    :type master_results_dataframe: _type_\n",
    "    :return: _description_\n",
    "    :rtype: _type_\n",
    "    \"\"\"\n",
    "\n",
    "    gridsearch = False # set to True if you want to use gridsearch\n",
    "\n",
    "    if model not in ['decision_tree', 'random_forest', 'knn', 'svm', 'gradientboostingclassifier', 'adaboost', 'bagging', 'extra_trees', 'gaussian_nb', 'bernoulli_nb', 'multinomial_nb', 'linear_svc', 'xgboost']:\n",
    "        # evaluate the model\n",
    "        acc_score = accuracy_score(y_test, y_pred) # accuracy score for the model on the testing set\n",
    "        cross_val = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # root mean squared error on the testing set\n",
    "        mae = mean_absolute_error(y_test, y_pred) # on the testing set\n",
    "        r2 = r2_score(y_test, y_pred) #\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        model_name = str(model).lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "        \n",
    "        print(f'accuracy_score: {acc_score}')\n",
    "        print(f'cross_val_score: {cross_val}')\n",
    "        print(f'rmse: {rmse}')\n",
    "        print(f'mae: {mae}')\n",
    "        print(f'r2: {r2}')\n",
    "        print(f'mse: {mse}')\n",
    "        print(f'auc: {auc_score}')\n",
    "        # print(f'false positive rate: {fpr}')\n",
    "        # print(f'true positive rate: {tpr}')\n",
    "        print(f'thresholds: {thresholds}')\n",
    "\n",
    "        # AUC and ROC\n",
    "        # calculate the probabilities\n",
    "        try:\n",
    "            y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "            # calculate the false positive rate and true positive rate\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "            # calculate the area under the curve\n",
    "            print(f'AUC score: {auc(fpr, tpr)}')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            y_pred_prob = ''\n",
    "            fpr, tpr, thresholds = '', '', ''\n",
    "            auc_score = ''\n",
    "            print(f'Initialized all of the following to None: y_pred_prob, fpr, tpr, thresholds, auc_score')\n",
    "\n",
    "        #  train score\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        # test score\n",
    "        test_score = model.score(X_test, y_test)\n",
    "\n",
    "        # perform grid search to find the best parameters\n",
    "        # create a dictionary of parameters to search (for a logistic regression model)\n",
    "        if gridsearch:\n",
    "            try:\n",
    "                print('Performing Grid Search...')\n",
    "                # find the parameters dict that matches the model name in the dictionary of parameters, and assign it to params\n",
    "                params = param_defaults.get(model_name) # get the parameters for the model\n",
    "                cv_num = 3 # number of cross validations to perform\n",
    "                print('Parameters for the model: ', params)\n",
    "                print(f'Estimated time to complete grid search: {len(params)*cv_num} seconds')\n",
    "                # create a grid search object\n",
    "                grid_search = GridSearchCV(model, params, cv=cv_num, verbose=0, n_jobs=-1)\n",
    "                # fit the grid search object to the training data\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                # get the best parameters\n",
    "                best_params = grid_search.best_params_\n",
    "                # get the best score\n",
    "                best_score = grid_search.best_score_\n",
    "                print(f'best parameters: {best_params}')\n",
    "                print(f'best score: {best_score}')\n",
    "                # best params\n",
    "                best_params = model.best_params_\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                best_params = None\n",
    "                best_score = None\n",
    "        else:\n",
    "            best_params = None\n",
    "            best_score = None\n",
    "        # add the results to the master results dataframe using concat\n",
    "        master_results_dataframe = pd.concat([master_results_dataframe, pd.DataFrame({ 'model': [model_name], 'accuracy_score': [acc_score], 'cross_val_score': [cross_val], 'rmse': [rmse], 'mae': [mae], 'r2': [r2], 'mse': [mse], 'auc': [auc_score], 'precision': [precision], 'recall': [recall], 'f1': [f1], 'train_score': [train_score], 'test_score': [test_score], 'best_params': [best_params], 'best_score': [best_score], 'residuals': [y_test - y_pred] })], ignore_index=True)\n",
    "        # save the model and the master results dataframe as a pickle file\n",
    "\n",
    "        pickle.dump(model, open(f'../models/{model_name}.pkl', 'wb'))\n",
    "        # plot the ROC curve\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{model} ROC Curve')\n",
    "        # save the plot as a png file\n",
    "        plt.savefig(f'../images/{model}_roc_curve.png')\n",
    "        plt.show(); # the ROC curve is a plot of the true positive rate against the false positive rate\n",
    "    return master_results_dataframe\n",
    "\n",
    "# checking function for data integrity\n",
    "def check_xtrain_is_same(X_train, original_X_train):\n",
    "    if X_train.equals(original_X_train):\n",
    "        return True #  X_train is the same as original_X_train\n",
    "    else:\n",
    "        return False #  X_train is not the same as original_X_train\n",
    "\n",
    "def pre_test(original_X_train, original_X_test, y_train, y_test, model, param_defaults):\n",
    "    # model = AdaBoostClassifier()\n",
    "\n",
    "    X_train = original_X_train # set to the originals\n",
    "    X_test = original_X_test\n",
    "\n",
    "    if not check_xtrain_is_same(X_train, original_X_train):\n",
    "        raise Exception('X_train has been modified')\n",
    "\n",
    "\n",
    "    # Feature Selection using SelectKBest\n",
    "    # import SelectKBest\n",
    "\n",
    "    # create a SelectKBest object to select features with two best ANOVA F-Values\n",
    "    fvalue_selector = SelectKBest(f_classif, k=4) # 4 features with the highest scores are selected\n",
    "    # apply the SelectKBest object to the features and target\n",
    "    X_kbest = fvalue_selector.fit_transform(X_train, y_train)\n",
    "    # create a list of the selected features\n",
    "    selected_features = X_train.columns[fvalue_selector.get_support()]\n",
    "    # create a list of the non-selected features\n",
    "    non_selected_features = X_train.columns[~fvalue_selector.get_support()]\n",
    "    # score the model with the selected features\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, model, param_defaults\n",
    "\n",
    "def remove_vif(X_train, X_test, thresh=10, top_n = 10):\n",
    "    # calculate VIF (variance inflation factor)\n",
    "    \n",
    "    # make a list of top 50 words that are in the top 50 words in the count vectorizer\n",
    "    top_n_words = list(X_train.sum().sort_values(ascending=False).head(top_n).index)\n",
    "    \n",
    "    print('Calculating VIF... for the top {} words'.format(top_n))\n",
    "    # load the already calculated VIFs from the pickle file if it exists\n",
    "    try:\n",
    "        previously_dropped = pickle.load(open('../data/vif.pkl', 'rb'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        previously_dropped = pd.DataFrame()\n",
    "        print('vif.pkl does not exist. Creating a new vif dataframe.')\n",
    "        \n",
    "    length_of_loop = len(top_n_words)\n",
    "    \n",
    "    X_train_original = X_train.copy()\n",
    "    X_test_original = X_test.copy()\n",
    "    X_train = X_train[top_n_words]\n",
    "    X_test = X_test[top_n_words]\n",
    "    \n",
    "    for feature in tqdm(X_train.columns):\n",
    "        # if we have not already calculated the VIF for this feature (i.e. it is not in the vif dataframe)\n",
    "        if feature not in previously_dropped.columns:\n",
    "            # calculate the VIF for this feature\n",
    "            vif_feature = pd.Series([variance_inflation_factor(X_train.values, X_train.columns.get_loc(feature))], index=[feature]) # calculate the VIF for this feature\n",
    "            # if the VIF is greater than the threshold\n",
    "            if vif_feature[feature] > thresh:\n",
    "                # add the feature to the vif dataframe with the feature name as the column name and the VIF as the value\n",
    "                previously_dropped = pd.concat([previously_dropped, vif_feature], axis=1)\n",
    "                # drop the feature from the X_train and X_test dataframes\n",
    "                X_train_original.drop(feature, axis=1, inplace=True)\n",
    "                X_test_original.drop(feature, axis=1, inplace=True)\n",
    "                print(f'Dropped {feature} from the dataframes.')\n",
    "                # save the vif dataframe as a pickle file\n",
    "                pickle.dump(previously_dropped, open('../data/vif.pkl', 'wb'))\n",
    "            else: # if the VIF is less than the threshold\n",
    "                # pass and continue to the next feature\n",
    "                pass\n",
    "        else: # we have already calculated the VIF for this feature\n",
    "            # pass and continue to the next feature\n",
    "            print(f'Already calculated VIF for {feature}.')\n",
    "    \n",
    "    # now drop any of the features \n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def remove_correlated_features(X_train, X_test, thresh=0.8):\n",
    "    # calculate the correlation matrix\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    # create a mask to select upper triangle of correlation matrix\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    # select the upper triangle of the correlation matrix\n",
    "    upper = corr_matrix.mask(mask)\n",
    "    # find the features with correlation greater than the threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n",
    "    # drop the features in the to_drop list from the X dataframe\n",
    "    X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    return X_train, X_test\n",
    "\n",
    "def remove_low_variance_features(X_train, X_test, thresh=0.0):\n",
    "    # create a VarianceThreshold object with a threshold of 0.8\n",
    "    sel = VarianceThreshold(threshold=thresh)\n",
    "    # fit the selector to the features\n",
    "    sel.fit(X_train)\n",
    "    # get the support of the features\n",
    "    support = sel.get_support()\n",
    "    # get the features that are not constant\n",
    "    non_constant_features = X_train.columns[support]\n",
    "    # get the features that are constant\n",
    "    constant_features = [feat for feat in X_train.columns if feat not in non_constant_features]\n",
    "    # drop the constant features from the X dataframe\n",
    "    X_train.drop(constant_features, axis=1, inplace=True)\n",
    "    X_test.drop(constant_features, axis=1, inplace=True)\n",
    "    return X_train, X_test\n",
    "\n",
    "def remove_low_information_features(X_train, X_test, thresh=0.8):\n",
    "    # create a list to store the low information features\n",
    "    low_information_cols = []\n",
    "    # iterate over each feature in the X dataframe\n",
    "    for col in X_train.columns:\n",
    "        # calculate the ratio\n",
    "        ratio = X_train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "        # if the ratio is greater than or equal to the threshold\n",
    "        if ratio >= thresh:\n",
    "            # append the column name to the low_information_cols list\n",
    "            low_information_cols.append(col)\n",
    "    # drop the low information features from the X dataframe\n",
    "    X_train.drop(low_information_cols, axis=1, inplace=True)\n",
    "    X_test.drop(low_information_cols, axis=1, inplace=True)\n",
    "    return X_train, X_test\n",
    "\n",
    "def remove_highly_correlated_features(X_train, X_test, thresh=0.8):\n",
    "    # calculate the correlation matrix\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    # create a mask to select upper triangle of correlation matrix\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    # select the upper triangle of the correlation matrix\n",
    "    upper = corr_matrix.mask(mask)\n",
    "    # find the features with correlation greater than the threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n",
    "    # drop the features in the to_drop list from the X dataframe\n",
    "    X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the premodeling notebook\n",
    "df_reddit = pd.read_csv('../data/df_outliers_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  ability  able  absolutely  abuse  accept  accidentally  account  act  \\\n",
       "0    0        0     0           1      0       0             0        0    0   \n",
       "1    0        0     0           0      0       0             0        0    0   \n",
       "2    0        0     0           0      0       0             0        0    0   \n",
       "3    0        0     0           0      0       0             0        0    0   \n",
       "4    0        0     0           0      0       0             0        0    0   \n",
       "\n",
       "   acting  ...  yeah  year  years  yes  yesterday  yo  young  younger  youre  \\\n",
       "0       0  ...     0     0      0    0          0   0      0        0      1   \n",
       "1       0  ...     0     0      0    0          0   0      0        0      0   \n",
       "2       0  ...     0     0      0    0          0   0      0        0      0   \n",
       "3       0  ...     0     0      0    0          0   0      0        0      0   \n",
       "4       0  ...     0     0      0    0          0   0      0        0      0   \n",
       "\n",
       "   youtube  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "# fit and transform the count vectorizer on the selftext column\n",
    "try:\n",
    "    X = count_vectorizer.fit_transform(df_reddit['selftext']) # X is a sparse matrix\n",
    "except:\n",
    "    print('There was an error')\n",
    "    X = None\n",
    "if X is not None:\n",
    "    # convert to dense\n",
    "    X = X.todense() # X is now a dense matrix, which means it is no longer sparse and has no zeros\n",
    "    # convert to a dataframe and set the column names to the words in the count vectorizer\n",
    "    X = pd.DataFrame(X, columns=count_vectorizer.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataframe: (6299, 1000)\n",
      "Dimensions of the dataframe: (6299, 1001)\n",
      "Dimensions of the training set: (5039, 1000)\n",
      "Dimensions of the testing set: (1260, 1000)\n"
     ]
    }
   ],
   "source": [
    "# check the dimensions of the dataframe\n",
    "if X.shape[0] != df_reddit.shape[0]:\n",
    "    print('The dataframe dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the dataframe: {X.shape}')\n",
    "# X.head(5)\n",
    "# Now we want to add the target column to the X dataframe so that we can use it to train the model\n",
    "# add the target column to the X dataframe (the target column is the subreddit column from the df_reddit dataframe)\n",
    "X['subreddit_target'] = df_reddit['target']\n",
    "# check the dimensions of the dataframe\n",
    "if X.shape[0] != df_reddit.shape[0]:\n",
    "    print('The dataframe dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the dataframe: {X.shape}')\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop('subreddit_target', axis=1), X['subreddit_target'], test_size=0.2, random_state=42)\n",
    "# check the dimensions of the training and testing sets\n",
    "if X_train.shape[0] != y_train.shape[0]:\n",
    "    print('The training set dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the training set: {X_train.shape}')\n",
    "if X_test.shape[0] != y_test.shape[0]:\n",
    "    print('The testing set dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the testing set: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the original x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Establish original_X_train and original_X_test\n",
    "original_X_train = X_train\n",
    "original_X_test = X_test\n",
    "vif_dropped = [] # list to store the features that were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating VIF... for the top 500 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60/500 [00:32<04:10,  1.76it/s]"
     ]
    }
   ],
   "source": [
    "# implementing the vif function on the top_50_words only (this will be used to drop features)\n",
    "if vif_dropped == []: # if the list is empty\n",
    "    X_train, X_test = remove_vif(X_train, X_test, 4, 500) # remove features with VIF greater than 5\n",
    "    vif_dropped.append(X_train.columns) # append the features that were dropped to the vif_dropped list\n",
    "else:\n",
    "    print('The VIF function has already been run!')\n",
    "# implementing the remove_low_variance_features function\n",
    "# purpose: remove features with a variance of zero (i.e. features that have the same value for all observations)\n",
    "X_train, X_test = remove_low_variance_features(X_train, X_test, 0.0) # remove features with a variance of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the names of the features that were removed so we can perform this step only once.\n",
    "vif_dropped = [col for col in original_X_train.columns if col not in X_train.columns] # list of features that were removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model Results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model results df\n",
    "master_results_dataframe = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1', 'auc', 'cross_val_score', 'rmse', 'mae', 'r2','mse', 'time','train_score', 'test_score', 'best_params', 'residuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder() # purpose: encode the target column\n",
    "y_train = encoder.fit_transform(y_train) # fit and transform the target column on the training set (i.e. the target column is the subreddit column from the df_reddit dataframe). This is done so that the model can understand the target column, which is a string and not a number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "This classifier is very easily affected by mulcollinearity, as its name implies, it is \"naive\" and assumes that the features are independent of each other. It is also very fast to train and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a special dataset for the naive bayes model that is clean of any multicollinearity\n",
    "correlations = X_train.corr() # calculate the correlation matrix\n",
    "correlations = correlations.abs() # absolute value of the correlations (i.e. no negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the training set: (5039, 50)\n",
      "Dimensions of the testing set: (1260, 50)\n",
      "Features removed: []\n"
     ]
    }
   ],
   "source": [
    "# remove any features with a correlation greater than 0.75 from this models training and testing sets\n",
    "nb_X_train = X_train.copy()\n",
    "nb_X_test = X_test.copy()\n",
    "# create a list of the columns to remove\n",
    "cols_to_remove = [] # create an empty list\n",
    "# loop through the columns in the correlation matrix\n",
    "for col in correlations: # for each column in the correlation matrix\n",
    "    # loop through the correlation values of the columns\n",
    "    for i in range(len(correlations[col])):\n",
    "        # if the correlation value is greater than 0.75 and the column is not the same as the index\n",
    "        if correlations[col][i] > 0.75 and col != correlations.index[i]:\n",
    "            # add the column to the list of columns to remove\n",
    "            cols_to_remove.append(col)\n",
    "# remove the columns from the training and testing sets\n",
    "nb_X_train.drop(cols_to_remove, axis=1, inplace=True)\n",
    "nb_X_test.drop(cols_to_remove, axis=1, inplace=True)\n",
    "# check the dimensions of the training and testing sets\n",
    "if nb_X_train.shape[0] != y_train.shape[0]:\n",
    "    print('The training set dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the training set: {nb_X_train.shape}')\n",
    "if nb_X_test.shape[0] != y_test.shape[0]:\n",
    "    print('The testing set dimensions do not match!')\n",
    "else:\n",
    "    print(f'Dimensions of the testing set: {nb_X_test.shape}')\n",
    "\n",
    "# which features did we remove?\n",
    "print(f'Features removed: {cols_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.846031746031746\n",
      "cross_val_score: 0.8319107517220724\n",
      "rmse: 0.3923878871324317\n",
      "mae: 0.15396825396825398\n",
      "r2: 0.3588879417743098\n",
      "mse: 0.15396825396825398\n",
      "auc: 0.8652940790767818\n",
      "thresholds: [2 1 0]\n",
      "AUC score: 0.8925486853321094\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# create a Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "model = gnb\n",
    "\n",
    "X_train, X_test, y_train, y_test, model, param_defaults = pre_test(X_train, X_test, y_train, y_test, model, param_defaults)\n",
    "\n",
    "# fit the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "master_results_dataframe = save_results(model,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train, param_defaults,gridsearch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance by Permutation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_67948/183319040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperm_imp_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportances_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m plt.boxplot(result.importances[perm_imp_idx].T, vert=False,\n\u001b[1;32m      5\u001b[0m             labels=X.columns[perm_imp_idx])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(model, X.values, y, n_repeats=10, random_state=42)\n",
    "\n",
    "perm_imp_idx = result.importances_mean.argsort()\n",
    "plt.boxplot(result.importances[perm_imp_idx].T, vert=False,\n",
    "            labels=X.columns[perm_imp_idx])\n",
    "plt.title('Feature Importance from Rain in Australia Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "X_train = original_X_train # set to the originals\n",
    "X_test = original_X_test\n",
    "\n",
    "\n",
    "if not check_xtrain_is_same(X_train, original_X_train):\n",
    "    raise Exception('X_train has been modified')\n",
    "\n",
    "# create a SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(f_classif, k=4) # 4 features with the highest scores are selected\n",
    "\n",
    "# apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X_train, y_train)\n",
    "# create a list of the selected features\n",
    "selected_features = X_train.columns[fvalue_selector.get_support()]\n",
    "# create a list of the non-selected features\n",
    "non_selected_features = X_train.columns[~fvalue_selector.get_support()]\n",
    "# score the model with the selected features\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the training data to make sure it is the same as the testing data\n",
    "\n",
    "# create a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "# fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "# score the model on the training data\n",
    "logreg.score(X_train, y_train)\n",
    "# score the model on the testing data\n",
    "logreg.score(X_test, y_test)\n",
    "# predict the target values for the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "# create a confusion matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# create a classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# create a dataframe of the coefficients\n",
    "coefficients = pd.DataFrame({'feature': X_train.columns, 'coefficient': logreg.coef_[0]})\n",
    "# sort the coefficients by their magnitude\n",
    "coefficients.sort_values('coefficient', ascending=False, inplace=True)\n",
    "# plot the coefficients\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(coefficients['feature'], coefficients['coefficient'])\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.savefig('../images/logreg_coefficients.png')\n",
    "plt.show();\n",
    "master_results_dataframe = save_results(logreg,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train, param_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Gradient Boosting classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "model = gbc\n",
    "\n",
    "X_train, X_test, y_train, y_test, model, param_defaults = pre_test(X_train, X_test, y_train, y_test, model, param_defaults)\n",
    "\n",
    "# fit the model on the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "master_results_dataframe = save_results(model,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train, param_defaults)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create a random forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "model = rfc\n",
    "\n",
    "X_train, X_test, y_train, y_test, model, param_defaults = pre_test(X_train, X_test, y_train, y_test, model, param_defaults)\n",
    "\n",
    "# fit the model on the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "master_results_dataframe = save_results(model,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train, param_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "*note: be sure to scale before using decision trees*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# create a Decision Tree classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "model = dtc\n",
    "\n",
    "X_train, X_test, y_train, y_test, model, param_defaults = pre_test(X_train, X_test, y_train, y_test, model, param_defaults)\n",
    "\n",
    "#note: Be sure to scale the data before using SVM\n",
    "X_train_sc = sc.fit_transform(X_train) # fit and transform the training data\n",
    "X_test_sc = sc.transform(X_test) # transform the testing data\n",
    "\n",
    "\n",
    "# fit the model on the training data\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# predict on the testing data\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(f'Preparing The Results')\n",
    "master_results_dataframe = save_results(model,master_results_dataframe, y_test, y_pred, X_train, X_test, y_train, param_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_results_dataframe.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
