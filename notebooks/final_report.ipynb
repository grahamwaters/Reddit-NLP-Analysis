{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel base (Python 3.9.6) is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel base (Python 3.9.6) is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def get_keywords(post):\n",
    "    \"\"\"Get the keywords from a post\"\"\"\n",
    "    # Get the keywords from the post\n",
    "    keywords = set()\n",
    "    for word in re.split(\"\\W+\", post.text):\n",
    "        if word in keywords:\n",
    "            continue\n",
    "        else:\n",
    "            keywords.add(word)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove Punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from a string\"\"\"\n",
    "    return ''.join(ch for ch in text if ch not in stop_words)\n",
    "\n",
    "# Lower Case\n",
    "def lowercase(text):\n",
    "    \"\"\"Lower case a string\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "# opening the scraped data saved in csv files and creating a dataframe for each\n",
    "df_ocd = pd.read_csv('./data/ocd_thread.csv')\n",
    "df_autism = pd.read_csv('./data/autism_thread.csv')\n",
    "\n",
    "# creating a target column for each dataframe\n",
    "df_ocd['target'] = 1\n",
    "df_autism['target'] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel base (Python 3.9.6) is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_ocd.drop(columns=('self_text', 'author'), axis=1), df_ocd.target)\n",
    "accuracy = accuracy_score(lr.predict(df_ocd.drop(columns=('self_text', 'author'), axis=1)), df_ocd.target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel base (Python 3.9.6) is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "adaboost.fit(df_ocd.drop(columns=('self_text', 'author'), axis=1), df_ocd.target)\n",
    "accuracy = accuracy_score(adaboost.predict(df_ocd.drop(columns=('self_text', 'author'), axis=1)), df_ocd.target)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(df_ocd.drop(columns=('self_text', 'author'), axis=1), df_ocd.target)\n",
    "accuracy = accuracy_score(dt.predict(df_ocd.drop(columns=('self_text', 'author'), axis=1)), df_ocd.target)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_ocd.drop(columns=('self_text', 'author'), axis=1).astype(str))\n",
    "tf_vocab = Counter().most_common(len(stop_words)+5)\n",
    "for i in range(10):\n",
    "    print(i, len(set(tokens)))\n",
    "    for j, k in enumerate(tf_vocab):\n",
    "        if k >= 5:\n",
    "            break\n",
    "        X_k = np.array(np.where(X == k))\n",
    "        X_j = np.zeros((0, 0))\n",
    "        for x in X_k:\n",
    "            X_j += 1 * x\n",
    "        X = np.vstack((X, X_j))\n",
    "    print(i + 1, len(set(tokens)))\n",
    "    for j, k in enumerate(tf_vocab):\n",
    "        if k > 4:\n",
    "            break\n",
    "        X_k = np.array(np.where(X == k))\n",
    "        X_j = np.zeros((0, 0))\n",
    "        for x in X_k:\n",
    "            X_j += 1 * x\n",
    "        X = np.hstack((X, X_j))\n",
    "        print(i + 2, len(set(tokens)))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "x = df_ocd.target.values\n",
    "y = lr.predict(x)\n",
    "bar_width = .35\n",
    "color_map = sns.light_palette(\"Greens\", 10)\n",
    "colors = color_map.as_hex()\n",
    "labels = list(range(len(df_ocd.target.index)))\n",
    "rects = ax.bar(labels, y, width=bar_width, label='Predicted Probability', edgecolor=None, align=\"center\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_yticks(np.arange(0, 1.05, .25))\n",
    "ax.set_xticklabels(list(df_ocd.target.index))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Logistic Regression Predictions\")\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "confusion_matrix = pd.crosstab(df_ocd.target, df_ocd.prediction)\n",
    "cm = confusion_matrix(df_ocd.target, df_ocd.prediction)\n",
    "num_classes = cm.sum(1).max()+1\n",
    "class_names = list(range(num_classes))\n",
    "row_positions = np.argsort(-df_ocd.target)\n",
    "col_indices = np.argpartition(df_ocd.target, -df_ocd.target.size-1)\n",
    "for row_number, col_name in zip(row_positions, class_names):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(2, num_classes, row_number)\n",
    "    cnt = conf_matrix.iloc.get_value(row_position=row_number, column_label=col_name)\n",
    "    ax.barh(class_names, cnt)\n",
    "    ax.set_ylabel(col_name)\n",
    "    ax.set_xlim(0, num_classes)\n",
    "    ax.set_xticks(np.arange(0, num_classes, 1))\n",
    "    ax.grid()\n",
    "    plt.savefig('images/logreg_confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the Dendogram\n",
    "linkage_obj = linkage(distance_func=euclidean)\n",
    "dendro = linkage_obj.apply(X)\n",
    "plt.figure()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e8cf12211551e1ecfb7b84827bd23b348fb076393a508e20e995a8149682546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
